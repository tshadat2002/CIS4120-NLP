{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4375b52",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "### Part 1: Bag-of-Word Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d428d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk_stop_words=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac9805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#good guy example from the slides.\n",
    "inputs=\"I am a good guy. She is a good lady. I and she are good people. He is also a good guy.\"\n",
    "tokenized=word_tokenize(inputs)\n",
    "tokenized=[w.lower() for w in tokenized]\n",
    "tokenized=[w for w in tokenized if w not in nltk_stop_words and w.isalpha()]\n",
    "print (\"token list:\",tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473622fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=Counter(tokenized)\n",
    "print (\"token & frequency:\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"most common tokens:\",count.most_common(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84df116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's use PD format.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d74ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#generate CountVectorizer object.\n",
    "coun_vect = CountVectorizer(\n",
    "        \n",
    ")\n",
    "\n",
    "#Some parameters you can adjust inside.\n",
    "#lowercase\n",
    "#stop_words\n",
    "#min_df\n",
    "#max_df\n",
    "#ngram_range\n",
    "#and etc\n",
    "\n",
    "#For the entire list of all the parameters:\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060769d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_v2=pd.Series([\"I am a good guy. She is a good lady.\",\n",
    "              \"I and she are good people.\",\n",
    "              \"He is also a good guy.\"  \n",
    "              ])\n",
    "print (input_v2)\n",
    "print (input_v2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9fdafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#generate CountVectorizer object.\n",
    "coun_vect = CountVectorizer(lowercase=True,\n",
    "stop_words='english'\n",
    ")\n",
    "\n",
    "#convert strings to numerical vectors.\n",
    "count_matrix = coun_vect.fit_transform(input_v2)\n",
    "print (count_matrix)\n",
    "\n",
    "\n",
    "#CountVetorizer automatically removes single character words, apply lower-casing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f88b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the unique words.\n",
    "print(\"Unique Vocabulary: \", coun_vect.vocabulary_)\n",
    "print (len(coun_vect.vocabulary_))\n",
    "\n",
    "#show 2D array matrix.\n",
    "count_array = count_matrix.toarray()\n",
    "\n",
    "print(count_array)\n",
    "print (count_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc48423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 2D array matrix into Pandas DataFrame.\n",
    "bow_df = pd.DataFrame(count_array)\n",
    "\n",
    "# Map the column names to the corresponding words. \n",
    "bow_df.columns = coun_vect.get_feature_names()\n",
    "\n",
    "print(bow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e019c60c",
   "metadata": {},
   "source": [
    "### Part2: TF-IDF Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8cba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#generate TfidfVectorizer object.\n",
    "tfidf=TfidfVectorizer(\n",
    ")\n",
    "\n",
    "#For more parameter tunings:\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_list=[\"The apartment was clean and room was big.\",\n",
    "              \"The place was very clean and in a great neighborhood!\",\n",
    "              \"we stayed at a clean place \"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031f0c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create TfidfVectorizer object\n",
    "tf_vec = TfidfVectorizer(\n",
    "lowercase=True,\n",
    "stop_words='english',\n",
    "use_idf=True)\n",
    "\n",
    "# Generate matrix of word vectors\n",
    "tfidf_matrix = tf_vec.fit_transform(example_list)\n",
    "\n",
    "#Identify the unique words.\n",
    "print(\"Unique Vocabulary: \", tf_vec.vocabulary_)\n",
    "print (len(tf_vec.vocabulary_))\n",
    "\n",
    "#show 2D array matrix.\n",
    "tf_array = tfidf_matrix.toarray()\n",
    "\n",
    "print(tf_array)\n",
    "print (tf_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29158e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 2D array matrix into Pandas DataFrame.\n",
    "tf_df = pd.DataFrame(tf_array)\n",
    "\n",
    "# Map the column names to the corresponding words. \n",
    "tf_df.columns = tf_vec.get_feature_names()\n",
    "\n",
    "print(tf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d70a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to interpret the outputs:\n",
    "\n",
    "#so, tf-idf value for 1th word in 0th doc is 0.546.\n",
    "\n",
    "#clean and place should be less weighted than the words that appear fewer times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d669c817",
   "metadata": {},
   "source": [
    "## Part 3: Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6681674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    " \n",
    "# two np array\n",
    "A = np.array([1,3,6])\n",
    "B = np.array([-2,-4,6])\n",
    " \n",
    "print(\"A:\", A)\n",
    "print(\"B:\", B)\n",
    " \n",
    "# compute cosine similarity\n",
    "cos = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73feb6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "A=[1,3,6]\n",
    "B=[-2,-4,6]\n",
    "\n",
    "# compute cosine similarity\n",
    "cos=cosine_similarity([A],[B])\n",
    "print (cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fabe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2,1,2],[3,2,9], [-1,2,-3]])\n",
    "B = np.array([3,4,2])\n",
    "print(\"A:\\n\", A)\n",
    "print(\"B:\\n\", B)\n",
    " \n",
    "# compute cosine similarity\n",
    "cos = np.dot(A,B)/(norm(A, axis=1)*norm(B))\n",
    "print(\"Cosine Similarity:\\n\", cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9890b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[[2,1,2],[3,2,9], [-1,2,-3]]\n",
    "B=[3,4,2]\n",
    "\n",
    "print (A[0])\n",
    "print (B)\n",
    "\n",
    "for i in range(len(A)):\n",
    "    cos=cosine_similarity([A[i]],[B])\n",
    "    print (cos)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda19e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cos=[\"I am a good guy. She is a good lady.\",\n",
    "              \"I and she are good people.\",\n",
    "              \"He is also a good guy.\",\n",
    "                     \"I and she like a movie.\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate CountVectorizer object.\n",
    "coun_vect = CountVectorizer(\n",
    ")\n",
    "\n",
    "#convert strings to numerical vectors.\n",
    "count_matrix = coun_vect.fit_transform(input_cos)\n",
    "\n",
    "#Identify the unique words.\n",
    "print(\"Unique Vocabulary: \", coun_vect.vocabulary_)\n",
    "print (len(coun_vect.vocabulary_))\n",
    "\n",
    "#show 2D array matrix.\n",
    "count_array = count_matrix.toarray()\n",
    "\n",
    "print(count_array)\n",
    "print (count_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcfa470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos(A,B):\n",
    "    cos = np.dot(A,B)/(norm(A)*norm(B))\n",
    "    return cos\n",
    "\n",
    "print (cos(count_array[0],count_array[2]))\n",
    "print ()\n",
    "print (cos(count_array[0],count_array[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b270b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (cosine_similarity(count_array[[0]],count_array[[2]]))\n",
    "print (cosine_similarity(count_array[[0]],count_array[[3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a914b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (cosine_similarity(count_array,count_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2972b7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
